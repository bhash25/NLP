{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Aspect Term</th>\n",
       "      <th>polarity</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2339</td>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "      <td>neutral</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2339</td>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "      <td>positive</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1316</td>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "      <td>negative</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1316</td>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "      <td>negative</td>\n",
       "      <td>109</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1316</td>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>2272</td>\n",
       "      <td>We also use Paralles so we can run virtual mac...</td>\n",
       "      <td>Windows Server Enterprise 2003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>104</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>2272</td>\n",
       "      <td>We also use Paralles so we can run virtual mac...</td>\n",
       "      <td>Windows Server 2008 Enterprise</td>\n",
       "      <td>neutral</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>848</td>\n",
       "      <td>How Toshiba handles the repair seems to vary, ...</td>\n",
       "      <td>repair</td>\n",
       "      <td>conflict</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>848</td>\n",
       "      <td>How Toshiba handles the repair seems to vary, ...</td>\n",
       "      <td>repair</td>\n",
       "      <td>positive</td>\n",
       "      <td>130</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>734</td>\n",
       "      <td>I would like to use a different operating syst...</td>\n",
       "      <td>operating system</td>\n",
       "      <td>neutral</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2358 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           Sentence  \\\n",
       "0     2339  I charge it at night and skip taking the cord ...   \n",
       "1     2339  I charge it at night and skip taking the cord ...   \n",
       "2     1316  The tech guy then said the service center does...   \n",
       "3     1316  The tech guy then said the service center does...   \n",
       "4     1316  The tech guy then said the service center does...   \n",
       "...    ...                                                ...   \n",
       "2353  2272  We also use Paralles so we can run virtual mac...   \n",
       "2354  2272  We also use Paralles so we can run virtual mac...   \n",
       "2355   848  How Toshiba handles the repair seems to vary, ...   \n",
       "2356   848  How Toshiba handles the repair seems to vary, ...   \n",
       "2357   734  I would like to use a different operating syst...   \n",
       "\n",
       "                         Aspect Term  polarity  from   to  \n",
       "0                               cord   neutral    41   45  \n",
       "1                       battery life  positive    74   86  \n",
       "2                     service center  negative    27   41  \n",
       "3                       \"sales\" team  negative   109  121  \n",
       "4                           tech guy   neutral     4   12  \n",
       "...                              ...       ...   ...  ...  \n",
       "2353  Windows Server Enterprise 2003   neutral   104  134  \n",
       "2354  Windows Server 2008 Enterprise   neutral   140  170  \n",
       "2355                          repair  conflict    24   30  \n",
       "2356                          repair  positive   130  136  \n",
       "2357                operating system   neutral    32   48  \n",
       "\n",
       "[2358 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative', 'conflict'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sheth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sheth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sheth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessData:\n",
    "    def __init__(self) -> None:\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.word_lemmetizer = WordNetLemmatizer()\n",
    "\n",
    "    def lower_text(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_stop_words(self, text):\n",
    "        return [words for words in text if words.lower() not in self.stop_words]\n",
    "    \n",
    "    def remove_char(self, text):\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    def remove_num(self, text):\n",
    "        return re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    def tokenize_text(self, text):\n",
    "        return word_tokenize(text)\n",
    "    \n",
    "    def lemmetize_text(self, text):\n",
    "        return [self.word_lemmetizer.lemmatize(word) for word in text]\n",
    "    \n",
    "    def preprocess_data(self, text):  # Changed from preprocess_data to preprocess_data\n",
    "        text = self.lower_text(text)\n",
    "        text = self.remove_num(text)\n",
    "        text = self.remove_char(text)\n",
    "        text = self.tokenize_text(text)\n",
    "        #text = self.remove_stop_words(text)\n",
    "        text = self.lemmetize_text(text)\n",
    "\n",
    "        preprocessed_text = \" \".join(text)\n",
    "\n",
    "        return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence     Aspect Term  polarity\n",
      "0  i charge it at night and skip taking the cord ...            cord   neutral\n",
      "1  i charge it at night and skip taking the cord ...    battery life  positive\n",
      "2  the tech guy then said the service center doe ...  service center  negative\n",
      "3  the tech guy then said the service center doe ...       sale team  negative\n",
      "4  the tech guy then said the service center doe ...        tech guy   neutral\n"
     ]
    }
   ],
   "source": [
    "preprocessor = PreProcessData()\n",
    "\n",
    "df['Sentence'] = df['Sentence'].apply(preprocessor.preprocess_data)\n",
    "df['Aspect Term'] = df['Aspect Term'].apply(preprocessor.preprocess_data)\n",
    "\n",
    "print(df[['Sentence', 'Aspect Term', 'polarity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referred scikit-learn documentation\n",
    "\n",
    "X = df['Sentence'] + ' ' + df['Aspect Term']\n",
    "y = df['polarity'].fillna(\"unknown\")\n",
    "tfidf_vectorizer =  TfidfVectorizer()\n",
    "chi_selector = SelectKBest(chi2, k=100)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "X_selected = chi_selector.fit_transform(X_tfidf, y)\n",
    "\n",
    "\n",
    "X_tfidf_train, X_tfidf_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25, random_state=5624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLoVe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_path = 'glove.6B.300d.txt'\n",
    "if not os.path.exists(glove_path):\n",
    "    url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "    r = requests.get(url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall()\n",
    "\n",
    "# referred https://gist.github.com/sebtheiler/84a0c5afac04f7e602de350ddca94859#file-loading_vectors_full-py\n",
    "glove = {}\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove[word] = vector\n",
    "\n",
    "print(f\"Loaded {len(glove)} word vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embedding(text):\n",
    "    words = text.split()\n",
    "    embeddings = [glove.get(word) for word in words if word in glove]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(glove['the'].shape)\n",
    "    \n",
    "X_glove = X.apply(text_to_embedding)\n",
    "X_glove_train, X_glove_test, y_train, y_test = train_test_split(X_glove, y, test_size=0.25, random_state=5624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\sheth\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.25.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sheth\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f14d4676ab24a6fbd9eaf49a6e8115e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# referred the following link https://github.com/UKPLab/sentence-transformers\n",
    "%pip install sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "bert = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "X_bert = bert.encode(X.to_list(), show_progress_bar=True)\n",
    "polarity_map = {'positive': 2, 'neutral': 1, 'negative': 0, 'conflict': 4}\n",
    "y_bert = y.map(polarity_map)\n",
    "X_bert_train, X_bert_test, y_train, y_test = train_test_split(X_bert, y, test_size=0.25, random_state=5624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM, MLP and Random Forest on TF-IDF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        11\n",
      "    negative       0.57      0.87      0.69       228\n",
      "     neutral       0.84      0.13      0.23       123\n",
      "    positive       0.70      0.68      0.69       228\n",
      "\n",
      "    accuracy                           0.63       590\n",
      "   macro avg       0.53      0.42      0.40       590\n",
      "weighted avg       0.67      0.63      0.58       590\n",
      "\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.33      0.09      0.14        11\n",
      "    negative       0.59      0.72      0.65       228\n",
      "     neutral       0.40      0.26      0.32       123\n",
      "    positive       0.68      0.68      0.68       228\n",
      "\n",
      "    accuracy                           0.60       590\n",
      "   macro avg       0.50      0.44      0.45       590\n",
      "weighted avg       0.58      0.60      0.58       590\n",
      "\n",
      "\n",
      "MLP Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.20      0.09      0.13        11\n",
      "    negative       0.58      0.87      0.70       228\n",
      "     neutral       0.61      0.16      0.26       123\n",
      "    positive       0.73      0.66      0.69       228\n",
      "\n",
      "    accuracy                           0.63       590\n",
      "   macro avg       0.53      0.45      0.44       590\n",
      "weighted avg       0.63      0.63      0.59       590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SVM Classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
    "svm_classifier.fit(X_tfidf_train, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_tfidf_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_tfidf_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_tfidf_test)\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "mlp_classifier.fit(X_tfidf_train, y_train)\n",
    "mlp_predictions = mlp_classifier.predict(X_tfidf_test)\n",
    "print(\"\\nMLP Classification Report:\")\n",
    "print(classification_report(y_test, mlp_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing SVM, MLP and Random Forest for TF-IDF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------+--------+----------+\n",
      "|   Classifier  | Accuracy | Precision | Recall | F1-Score |\n",
      "+---------------+----------+-----------+--------+----------+\n",
      "|      SVM      |  0.6254  |   0.6671  | 0.6254 |  0.5796  |\n",
      "| Random Forest |  0.5966  |   0.5792  | 0.5966 |  0.5809  |\n",
      "|      MLP      |  0.6288  |   0.6342  | 0.6288 |  0.5923  |\n",
      "+---------------+----------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Get metrics for each classifier\n",
    "svm_metrics = get_metrics(y_test, svm_predictions)\n",
    "rf_metrics = get_metrics(y_test, rf_predictions)\n",
    "mlp_metrics = get_metrics(y_test, mlp_predictions)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "table.add_row([\"SVM\"] + [f\"{metric:.4f}\" for metric in svm_metrics])\n",
    "table.add_row([\"Random Forest\"] + [f\"{metric:.4f}\" for metric in rf_metrics])\n",
    "table.add_row([\"MLP\"] + [f\"{metric:.4f}\" for metric in mlp_metrics])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_glove_train = np.array(X_glove_train.tolist())\n",
    "X_glove_test = np.array(X_glove_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM, MLP and Random Forest on GLoVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        11\n",
      "    negative       0.64      0.86      0.73       228\n",
      "     neutral       0.70      0.17      0.27       123\n",
      "    positive       0.71      0.79      0.75       228\n",
      "\n",
      "    accuracy                           0.67       590\n",
      "   macro avg       0.51      0.45      0.44       590\n",
      "weighted avg       0.67      0.67      0.63       590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        11\n",
      "    negative       0.71      0.75      0.73       228\n",
      "     neutral       0.79      0.33      0.47       123\n",
      "    positive       0.67      0.86      0.75       228\n",
      "\n",
      "    accuracy                           0.69       590\n",
      "   macro avg       0.54      0.49      0.49       590\n",
      "weighted avg       0.70      0.69      0.67       590\n",
      "\n",
      "\n",
      "MLP Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.21      0.27      0.24        11\n",
      "    negative       0.71      0.65      0.68       228\n",
      "     neutral       0.54      0.50      0.52       123\n",
      "    positive       0.71      0.79      0.75       228\n",
      "\n",
      "    accuracy                           0.67       590\n",
      "   macro avg       0.55      0.55      0.55       590\n",
      "weighted avg       0.67      0.67      0.67       590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
    "svm_classifier.fit(X_glove_train, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_glove_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_glove_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_glove_test)\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "mlp_classifier.fit(X_glove_train, y_train)\n",
    "mlp_predictions = mlp_classifier.predict(X_glove_test)\n",
    "print(\"\\nMLP Classification Report:\")\n",
    "print(classification_report(y_test, mlp_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing SVM, MLP and Random Forest for GLoVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GloVe Embeddings Performance Comparison:\n",
      "+---------------+----------+-----------+--------+----------+\n",
      "|   Classifier  | Accuracy | Precision | Recall | F1-Score |\n",
      "+---------------+----------+-----------+--------+----------+\n",
      "|      SVM      |  0.6712  |   0.6658  | 0.6712 |  0.6280  |\n",
      "| Random Forest |  0.6949  |   0.6968  | 0.6949 |  0.6716  |\n",
      "|      MLP      |  0.6678  |   0.6678  | 0.6678 |  0.6663  |\n",
      "+---------------+----------+-----------+--------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get metrics for each classifier\n",
    "svm_metrics = get_metrics(y_test, svm_predictions)\n",
    "rf_metrics = get_metrics(y_test, rf_predictions)\n",
    "mlp_metrics = get_metrics(y_test, mlp_predictions)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "table.add_row([\"SVM\"] + [f\"{metric:.4f}\" for metric in svm_metrics])\n",
    "table.add_row([\"Random Forest\"] + [f\"{metric:.4f}\" for metric in rf_metrics])\n",
    "table.add_row([\"MLP\"] + [f\"{metric:.4f}\" for metric in mlp_metrics])\n",
    "\n",
    "print(\"\\nGloVe Embeddings Performance Comparison:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM, MLP and Random Forest on S-BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        11\n",
      "    negative       0.73      0.87      0.79       228\n",
      "     neutral       0.75      0.33      0.46       123\n",
      "    positive       0.71      0.82      0.76       228\n",
      "\n",
      "    accuracy                           0.72       590\n",
      "   macro avg       0.55      0.51      0.50       590\n",
      "weighted avg       0.71      0.72      0.70       590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        11\n",
      "    negative       0.72      0.83      0.77       228\n",
      "     neutral       0.69      0.34      0.46       123\n",
      "    positive       0.72      0.83      0.77       228\n",
      "\n",
      "    accuracy                           0.71       590\n",
      "   macro avg       0.53      0.50      0.50       590\n",
      "weighted avg       0.70      0.71      0.69       590\n",
      "\n",
      "\n",
      "MLP Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    conflict       0.00      0.00      0.00        11\n",
      "    negative       0.74      0.78      0.76       228\n",
      "     neutral       0.62      0.52      0.57       123\n",
      "    positive       0.76      0.79      0.78       228\n",
      "\n",
      "    accuracy                           0.72       590\n",
      "   macro avg       0.53      0.52      0.52       590\n",
      "weighted avg       0.71      0.72      0.71       590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
    "svm_classifier.fit(X_bert_train, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_bert_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_bert_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_bert_test)\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "\n",
    "# MLP Classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "mlp_classifier.fit(X_bert_train, y_train)\n",
    "mlp_predictions = mlp_classifier.predict(X_bert_test)\n",
    "print(\"\\nMLP Classification Report:\")\n",
    "print(classification_report(y_test, mlp_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing SVM, MLP and Random Forest for S-BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Embeddings Performance Comparison:\n",
      "+---------------+----------+-----------+--------+----------+\n",
      "|   Classifier  | Accuracy | Precision | Recall | F1-Score |\n",
      "+---------------+----------+-----------+--------+----------+\n",
      "|      SVM      |  0.7237  |   0.7129  | 0.7237 |  0.6980  |\n",
      "| Random Forest |  0.7136  |   0.6994  | 0.7136 |  0.6911  |\n",
      "|      MLP      |  0.7169  |   0.7064  | 0.7169 |  0.7103  |\n",
      "+---------------+----------+-----------+--------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sheth\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_metrics = get_metrics(y_test, svm_predictions)\n",
    "rf_metrics = get_metrics(y_test, rf_predictions)\n",
    "mlp_metrics = get_metrics(y_test, mlp_predictions)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "table.add_row([\"SVM\"] + [f\"{metric:.4f}\" for metric in svm_metrics])\n",
    "table.add_row([\"Random Forest\"] + [f\"{metric:.4f}\" for metric in rf_metrics])\n",
    "table.add_row([\"MLP\"] + [f\"{metric:.4f}\" for metric in mlp_metrics])\n",
    "\n",
    "print(\"\\nBERT Embeddings Performance Comparison:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
